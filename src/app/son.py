import whisper
import pyaudio
import wave

# Load the Whisper model
model = whisper.load_model("base")



def record_audio(fichier_sortie="output.wav", duree=10, taux_echantillonnage=44100, canaux=1, taille_bloc=1024):
    """
    Enregistre un fichier audio en format WAV.

    :param fichier_sortie: Nom du fichier de sortie (par d√©faut "enregistrement.wav").
    :param duree: Dur√©e de l'enregistrement en secondes (par d√©faut 5 secondes).
    :param taux_echantillonnage: Taux d'√©chantillonnage en Hz (par d√©faut 44100).
    :param canaux: Nombre de canaux (1 pour mono, 2 pour st√©r√©o, par d√©faut 1).
    :param taille_bloc: Taille du bloc d'√©chantillons pour chaque lecture (par d√©faut 1024).
    """
    # Initialisation de PyAudio
    p = pyaudio.PyAudio()

    # Ouverture du flux d'entr√©e audio
    stream = p.open(format=pyaudio.paInt16,
                    channels=canaux,
                    rate=taux_echantillonnage,
                    input=True,
                    frames_per_buffer=taille_bloc)

    print("Enregistrement en cours...")

    frames = []

    # Enregistrement de l'audio
    for _ in range(0, int(taux_echantillonnage / taille_bloc * duree)):
        data = stream.read(taille_bloc)
        frames.append(data)

    # Arr√™t de l'enregistrement
    print("Enregistrement termin√©.")
    stream.stop_stream()
    stream.close()
    p.terminate()

    # Sauvegarder l'audio dans un fichier WAV
    with wave.open(fichier_sortie, 'wb') as wf:
        wf.setnchannels(canaux)
        wf.setsampwidth(p.get_sample_size(pyaudio.paInt16))
        wf.setframerate(taux_echantillonnage)
        wf.writeframes(b''.join(frames))

    print(f"Fichier audio sauvegard√© sous '{fichier_sortie}'")



def transcribe_audio(filename="output.wav"):
    print("üéß Transcription de l'audio en cours...")
    result = model.transcribe(filename)
    text = result["text"].strip()
    print(f"üîç Transcription d√©tect√©e : '{text}'")
    return text



